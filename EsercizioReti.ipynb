{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EsercizioReti.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LXiGzH3ubsQF"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wang-Kevin900/DataVisualization/blob/main/EsercizioReti.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUDrvVDi65qA"
      },
      "source": [
        "# Setup libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY_oA_b-6-z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b28dc162-49fe-49e3-b109-81d1a52bd973"
      },
      "source": [
        "!pip install bokeh\r\n",
        "!pip install altair\r\n",
        "!pip install plotly\r\n",
        "!pip install pandas\r\n",
        "!pip install datetime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.6/dist-packages (2.1.1)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh) (3.13)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh) (2.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from bokeh) (3.7.4.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.6/dist-packages (from bokeh) (20.8)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from bokeh) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from bokeh) (1.19.4)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.6/dist-packages (from bokeh) (5.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh) (1.1.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=16.8->bokeh) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->bokeh) (1.15.0)\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.6/dist-packages (4.1.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from altair) (0.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from altair) (2.6.0)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.6/dist-packages (from altair) (1.1.5)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from altair) (0.11.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from altair) (1.19.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from altair) (2.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18->altair) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18->altair) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->altair) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18->altair) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (4.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly) (1.15.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: datetime in /usr/local/lib/python3.6/dist-packages (4.3)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.6/dist-packages (from datetime) (5.2.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from datetime) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from zope.interface->datetime) (50.3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMMQ_L7Qb6Vu"
      },
      "source": [
        "# Get data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytCkpOk9_thE"
      },
      "source": [
        "Importing the various library needed to the program, importing the txt sheet where all the data are (format: date - hour - value) (as long there's new line to indicate that a set of value is done, the program will work no matter how the data is placed in the datasheet, it is fault resistant) and lastly creating all the needed variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p97s3MLTysk0",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d2cab4d4-6941-4a3b-be02-fbfa3b0051af"
      },
      "source": [
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "\n",
        "# get the data from the text file\n",
        "file_data = files.upload()\n",
        "# trasform the data got from the txt file to list, \n",
        "# so that in the next FOR cycle for trasforming the data is easier to read letter per letter\n",
        "string_datatext_value = list(file_data.values());"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f3771b50-33e8-49af-8d0e-edbd7f409aad\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f3771b50-33e8-49af-8d0e-edbd7f409aad\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Dati2Con2SerieAnalogicheEdUnaDigitale.txt to Dati2Con2SerieAnalogicheEdUnaDigitale (3).txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C490lpURb-UK"
      },
      "source": [
        "# Trasform Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOUkzqrgdYH4"
      },
      "source": [
        "Preparing the needed variable to trasform the data read from the datasheet, to lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fQWTMrNdXVg"
      },
      "source": [
        "# variable that indicate the number of symbols that compose a date&time\r\n",
        "date_format = 10\r\n",
        "time_format = 8\r\n",
        "\r\n",
        "# variable that will store every symbol read from the datasheet\r\n",
        "buffer_of_data = \"\"\r\n",
        "\r\n",
        "# variable that will store the name/title of the various couples of data\r\n",
        "element_name = \"No Name\"\r\n",
        "control_name_line = False\r\n",
        "\r\n",
        "# variable that will store any complete data with any of the following format (date, time, float)\r\n",
        "single_string_list_of_data = []\r\n",
        "\r\n",
        "# once a single line of data (couple of data) is done being stored, \r\n",
        "# divide them (because later they will be trasformed in a pandas dataframe)\r\n",
        "list_of_datetime = []\r\n",
        "list_of_float = []\r\n",
        "\r\n",
        "# list where the complete data (by group) will be stored\r\n",
        "data_list = []\r\n",
        "\r\n",
        "# variable that checks if it's the first cycle inside the for loop since it started reading \r\n",
        "# (this is to avoid to fill the data list, since it gets filled before each \"title\")\r\n",
        "first_read = True\r\n",
        "\r\n",
        "# divide a single line of data of the datasheet in 3 section, where each section has the following meaning,\r\n",
        "# Date, Time, Float; what this variable do, is basically acting as index \r\n",
        "# to indicate wich section we are currently reading in the datasheet\r\n",
        "single_index_data_value = 0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpksqVJpLDG2"
      },
      "source": [
        "from datetime import datetime\r\n",
        "\r\n",
        "# go through all the data, and return a list of the various couples of data\r\n",
        "for i in string_datatext_value[0]:\r\n",
        "  # 32 is a value ascii that means \"Space\"\r\n",
        "  # 9 is a value ascii that means \"Tab\"\r\n",
        "  # 13 is a value ascii that means \"Carriage Return\"\r\n",
        "  # 10 is a value ascii that means \"New Line\"\r\n",
        "  # Ignore all the \"special symbols\", and just get all the \"interesting\" data\r\n",
        "  if i != 32 and i != 9 and i != 13:\r\n",
        "    # read from string of data (taken from the datasheet) and store it\r\n",
        "    buffer_of_data = buffer_of_data + chr(i);\r\n",
        "\r\n",
        "    # if we are currently in the first section (date section)...\r\n",
        "    if single_index_data_value == 0:\r\n",
        "      # if the lenght of the collected data reached the date format, that means that we are done with the date section,\r\n",
        "      # also it means that the casting is possible\r\n",
        "      if len(buffer_of_data) == date_format or control_name_line == True:\r\n",
        "        if control_name_line:\r\n",
        "          if i == 10:\r\n",
        "            if first_read == False:\r\n",
        "              data_list.append([element_name, list_of_datetime.copy(), list_of_float.copy()])\r\n",
        "              list_of_datetime.clear()\r\n",
        "              list_of_float.clear()\r\n",
        "\r\n",
        "            element_name = buffer_of_data\r\n",
        "            buffer_of_data = \"\"\r\n",
        "            control_name_line = False\r\n",
        "        \r\n",
        "        elif control_name_line == False:\r\n",
        "          try:\r\n",
        "            single_string_list_of_data.append(datetime.strptime(buffer_of_data, \"%d-%m-%Y\").date())\r\n",
        "            first_read = False\r\n",
        "            # reset the buffer and pass to the next section\r\n",
        "            buffer_of_data = \"\"\r\n",
        "            single_index_data_value+=1\r\n",
        "\r\n",
        "          except:\r\n",
        "            control_name_line = True\r\n",
        "\r\n",
        "      # if the symbol we got from the reading equals 10 (new line), that means that the line we are currently in the file, hasn't any data, so clean the buffer and go on\r\n",
        "      elif i == 10:\r\n",
        "        buffer_of_data = \"\"\r\n",
        "\r\n",
        "    # if we are currently in the second section (time section)...\r\n",
        "    elif single_index_data_value == 1:\r\n",
        "      # if the lenght of the collected data reached the time format, that means that we are done with the time section,\r\n",
        "      # also it means that the casting is possible\r\n",
        "      if len(buffer_of_data) == time_format:\r\n",
        "        single_string_list_of_data.append(datetime.strptime(buffer_of_data, \"%H:%M:%S\").time())\r\n",
        "\r\n",
        "        # reset the buffer and pass to the next section\r\n",
        "        buffer_of_data = \"\"\r\n",
        "        single_index_data_value+=1\r\n",
        "\r\n",
        "    # if we are currently in the third section (float section)...\r\n",
        "    elif single_index_data_value == 2:\r\n",
        "      # if we detect a 10 (in ASCII means \"new line\"), that means we're done reading a single line of data\r\n",
        "      # and that we are done to also reading a single couple of data\r\n",
        "      if i == 10:\r\n",
        "        # Add the string to the string of data while also,\r\n",
        "        # Converting the value from string to float and replacing the \",\" in \".\" so that the casting is possible\r\n",
        "        single_string_list_of_data.append(float(buffer_of_data.replace(\",\", \".\")))\r\n",
        "        \r\n",
        "        # divide the couple of data into 2 different lists to prepare them to be converted into pandas dataframe\r\n",
        "        list_of_datetime.append(datetime.combine(single_string_list_of_data[0], single_string_list_of_data[1]))\r\n",
        "        list_of_float.append(single_string_list_of_data[2])\r\n",
        "        # reset the buffer and the single string of data list and return to the first section to read more data of other lines\r\n",
        "        buffer_of_data = \"\"\r\n",
        "        single_string_list_of_data.clear()\r\n",
        "        single_index_data_value = 0\r\n",
        "\r\n",
        "# add items for the last time in the list if the last element in the txt file doesn't have \\n \r\n",
        "# (the consequence is that the for loop is unable to store the last couple of data)\r\n",
        "if string_datatext_value[0][len(string_datatext_value)-1] != 10 and string_datatext_value[0][len(string_datatext_value)-1] != 13:\r\n",
        "  single_string_list_of_data.append(float(buffer_of_data.replace(\",\", \".\")))\r\n",
        "  list_of_datetime.append(datetime.combine(single_string_list_of_data[0], single_string_list_of_data[1]))\r\n",
        "  list_of_float.append(single_string_list_of_data[2])\r\n",
        "\r\n",
        "# add the last group of data since the for is unable to do it because it ads to the list only when it encounters a new \"title\"\r\n",
        "data_list.append([element_name, list_of_datetime.copy(), list_of_float.copy()])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "5K-HHSVZ6CXY",
        "outputId": "68b39955-1f79-44ca-d93a-fba3d6f2039c"
      },
      "source": [
        "i = 0\r\n",
        "\r\n",
        "print(\"Choose one of the following group of data to visualize:\")\r\n",
        "for data in data_list:\r\n",
        "  print(str(i)+ \") \"+ data[0])\r\n",
        "  i+=1\r\n",
        "\r\n",
        "while(True):\r\n",
        "  console_input = input()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Choose one of the following group of data to visualize:\n",
            "0) Grandezza1SondaSr(Sr)\n",
            "\n",
            "1) Grandezza2SondaSd(Sd)\n",
            "\n",
            "2) Grandezza3SondaDigitale\n",
            "\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \"\"\"\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ff152c857705>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mconsole_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf69MNz7ASNJ"
      },
      "source": [
        "Rearranging all the data in 2 list (datatime and float), while also doing the casting from string to the needed type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM_sz2jfPOdz"
      },
      "source": [
        "from datetime import datetime\r\n",
        "\r\n",
        "# go through all the data, and return a list of the various couples of data\r\n",
        "for i in string_datatext_value[0]:\r\n",
        "  # 32 is a value ascii that means \"Space\"\r\n",
        "  # 9 is a value ascii that means \"Tab\"\r\n",
        "  # 13 is a value ascii that means \"Carriage Return\"\r\n",
        "  # 10 is a value ascii that means \"New Line\"\r\n",
        "  # Ignore all the \"special symbols\", and just get all the \"interesting\" data\r\n",
        "  if i != 32 and i != 9 and i != 13:\r\n",
        "    # read from string of data (taken from the datasheet) and store it\r\n",
        "    buffer_of_data = buffer_of_data + chr(i);\r\n",
        "\r\n",
        "    # if we are currently in the first section (date section)...\r\n",
        "    if single_index_data_value == 0:\r\n",
        "      # if the lenght of the collected data reached the date format, that means that we are done with the date section,\r\n",
        "      # also it means that the casting is possible\r\n",
        "      if len(buffer_of_data) == date_format:\r\n",
        "        single_string_list_of_data.append(datetime.strptime(buffer_of_data, \"%d-%m-%Y\").date())\r\n",
        "\r\n",
        "        # reset the buffer and pass to the next section\r\n",
        "        buffer_of_data = \"\"\r\n",
        "        single_index_data_value+=1\r\n",
        "\r\n",
        "    # if we are currently in the second section (time section)...\r\n",
        "    elif single_index_data_value == 1:\r\n",
        "      # if the lenght of the collected data reached the time format, that means that we are done with the time section,\r\n",
        "      # also it means that the casting is possible\r\n",
        "      if len(buffer_of_data) == time_format:\r\n",
        "        single_string_list_of_data.append(datetime.strptime(buffer_of_data, \"%H:%M:%S\").time())\r\n",
        "\r\n",
        "        # reset the buffer and pass to the next section\r\n",
        "        buffer_of_data = \"\"\r\n",
        "        single_index_data_value+=1\r\n",
        "\r\n",
        "    # if we are currently in the third section (float section)...\r\n",
        "    elif single_index_data_value == 2:\r\n",
        "      # if we detect a 10 (in ASCII means \"new line\"), that means we're done reading a single line of data\r\n",
        "      # and that we are done to also reading a single couple of data\r\n",
        "      if i == 10:\r\n",
        "        # Add the string to the string of data while also,\r\n",
        "        # Converting the value from string to float and replacing the \",\" in \".\" so that the casting is possible\r\n",
        "        single_string_list_of_data.append(float(buffer_of_data.replace(\",\", \".\")))\r\n",
        "\r\n",
        "        # divide the couple of data into 2 different lists to prepare them to be converted into pandas dataframe\r\n",
        "        list_of_datetime.append(datetime.combine(single_string_list_of_data[0], single_string_list_of_data[1]))\r\n",
        "        list_of_float.append(single_string_list_of_data[2])\r\n",
        "\r\n",
        "        # reset the buffer and the single string of data list and return to the first section to read more data of other lines\r\n",
        "        buffer_of_data = \"\"\r\n",
        "        single_string_list_of_data.clear()\r\n",
        "        single_index_data_value = 0\r\n",
        "\r\n",
        "# add items for the last time in the list if the last element in the txt file doesn't have \\n \r\n",
        "# (the consequence is that the for loop is unable to store the last couple of data)\r\n",
        "if string_datatext_value[0][len(string_datatext_value)-1] != 10:\r\n",
        "  single_string_list_of_data.append(float(buffer_of_data.replace(\",\", \".\")))\r\n",
        "  list_of_datetime.append(datetime.combine(single_string_list_of_data[0], single_string_list_of_data[1]))\r\n",
        "  list_of_float.append(single_string_list_of_data[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul_RHsHNogdw"
      },
      "source": [
        "Convert all the lists (date list and value list) in Pandas DataFrame, then, visualize the list created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ88MkFqoaz0"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# convert the 2 lists in a pandas dataframe\n",
        "data = pd.DataFrame({'date': list_of_datetime,\n",
        "                     'value': list_of_float})\n",
        "\n",
        "# print out the datagram\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdWeg8krcwVE"
      },
      "source": [
        "# Draw Chart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZurDLmLdckQa"
      },
      "source": [
        "Draw the Chart using the Bokeh library (the reason why i used this library is because it is easily customizable and it supports the callback event, in wich though, you have to write the code in JS; there is a method to convert some data from JS data kernel to Python data kernel by using IPython, but because of google colab enviroment, wich for some reason doesn't work, it is not possible. (a solution is to install and use Jupyter Notebook))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jByfhOKU01MO"
      },
      "source": [
        "from bokeh.plotting import figure, output_file, show\n",
        "from bokeh.io import output_notebook\n",
        "from bokeh.models import ColumnDataSource, CustomJS, Button\n",
        "from bokeh.models.tools import *\n",
        "from bokeh.models.widgets import DataTable, TableColumn, DateFormatter\n",
        "from bokeh.layouts import row, column\n",
        "\n",
        "\n",
        "# Configure the default output state to generate output in notebook cells when show() is called. \n",
        "output_notebook()\n",
        "\n",
        "# ColumnDataSource is a special object, wich it is easy to share data between multiple plots and widgets\n",
        "# Also the same ColumnDataSource is used to drive multiple renderers, selections of the data source are also shared.\n",
        "source = ColumnDataSource(data)\n",
        "\n",
        "# select the desired tool that can be used with the chart\n",
        "chart_tools=\"pan, wheel_zoom, reset, hover, poly_select, box_select\"\n",
        "tooltip = HoverTool(\n",
        "    # specify wich type of info i want to show\n",
        "    tooltips=[\n",
        "        (\"index\", \"$index\"),\n",
        "        (\"Value\", \"@value{0.2f}\"),\n",
        "        (\"Date\", \"@date{%F}\"),\n",
        "    ],\n",
        "    # format the date in datetime type (the default is numerical format)\n",
        "    formatters={\n",
        "        '@date': 'datetime'\n",
        "    },\n",
        "    # display a tooltip whenever the cursor is vertically in line with a data point\n",
        "    mode='vline'\n",
        ")\n",
        "\n",
        "# prepare the chart with the selected options, and add the tooltip too while also activating wheel zoom tool by default\n",
        "main_chart = figure(title='Data Visualization', plot_width=1500, plot_height=400, y_axis_label='Values', x_axis_label='Date', x_axis_type='datetime',\n",
        "           tools=chart_tools, toolbar_location='above', tooltips=\"\", sizing_mode=\"scale_width\")\n",
        "main_chart.add_tools(tooltip)\n",
        "main_chart.toolbar.active_scroll = main_chart.select_one(WheelZoomTool)\n",
        "\n",
        "# draw in the chart both line and circle, so that the obtained effect is that of linked points\n",
        "symbol1 = main_chart.line(x='date', y='value', line_width=2, source=source)\n",
        "symbol2 = main_chart.circle(x='date', y='value', fill_color=\"white\", size=6, source=source)\n",
        "\n",
        "\n",
        "# create the source for table obj\n",
        "source_table = ColumnDataSource(data=dict(\n",
        "    Start_date=[],\n",
        "    End_date=[],\n",
        "    Max_value=[],\n",
        "    Average_value=[],\n",
        "    Area=[]\n",
        "))\n",
        "\n",
        "columns = [\n",
        "    TableColumn(field=\"Start_date\", title=\"Start_date\", formatter=DateFormatter(format=\"%m/%d/%Y - %H:%M:%S\")),\n",
        "    TableColumn(field=\"End_date\", title=\"End_date\", formatter=DateFormatter(format=\"%m/%d/%Y - %H:%M:%S\")),\n",
        "    TableColumn(field=\"Max_value\", title=\"Max_value\"),\n",
        "    TableColumn(field=\"Average_value\", title=\"Average_value\"),\n",
        "    TableColumn(field=\"Area\", title=\"Area\")\n",
        "]\n",
        "\n",
        "data_table = DataTable(columns=columns, source=source_table, width=700, height=250)\n",
        "\n",
        "\n",
        "# create a variable that simulate the \\n function, it gets passed as parameter in the save button \n",
        "# because in the customJS enviroment, the kernel can't read corretly \\n because it execute its function diretly in the code\n",
        "# instead of passing it as value, so we just pass its value in a variable so that the kernel doesn't read \\n directly\n",
        "break_lines = \"\\r\\n\"\n",
        "save_button = Button(label=\"Save Data!\", button_type=\"success\", height=50)\n",
        "\n",
        "\n",
        "# create the source for bar plot obj\n",
        "source_barplot = ColumnDataSource(data=dict(\n",
        "    name_bar=[\"Max Value\", \"Avarage Value\", \"Area\"],\n",
        "    value=[0, 0, 0]\n",
        "))\n",
        "bar_plot = figure(title=\"General Info\", y_range=source_barplot.data[\"name_bar\"], height=300, toolbar_location=None, tools=\"\")\n",
        "bar_plot.hbar(y=\"name_bar\", right=\"value\", source=source_barplot, width=20)\n",
        "bar_plot.ygrid.grid_line_color = None\n",
        "\n",
        "\n",
        "# Execute the JS code when the user select any data in the chart with the box select tool\n",
        "source.selected.js_on_change(\"indices\", CustomJS(args=dict(source=source, source_table=source_table, source_barplot=source_barplot), code=\"\"\"\n",
        "        // get the indices of the selectd data and sort them in ascending order\n",
        "        var inds = cb_obj.indices\n",
        "        inds.sort(function(a, b){return a-b})\n",
        "\n",
        "\n",
        "        // if the array is not empty (if it is empy, it means that no elements has been selected (occurs when the user select no element after having selected some element), \n",
        "        // with the consequence of not adding any element)\n",
        "        if (inds.length != 0){\n",
        "          // create various variable to store the data from the source (ColumnDataSource object)\n",
        "          var d1 = source.data\n",
        "          var d2 = source_table.data\n",
        "          var d3 = source_barplot.data\n",
        "\n",
        "\n",
        "          // get the first and end date (no need to any particular calculus because each data is already in order and unique)\n",
        "          var start_date = new Date(d1[\"date\"][inds[0]])\n",
        "          var end_date = new Date(d1[\"date\"][inds[inds.length-1]])\n",
        "\n",
        "\n",
        "          // get max value\n",
        "          var max_value\n",
        "          for(var i = 0; i < inds.length; i++) {\n",
        "              if(i == 0) {\n",
        "                max_value = d1[\"value\"][inds[i]]\n",
        "              } else {\n",
        "                if(max_value < d1[\"value\"][inds[i]]){\n",
        "                  max_value = (d1[\"value\"][inds[i]]).toFixed(2)\n",
        "                }\n",
        "              }\n",
        "          }\n",
        "\n",
        "\n",
        "          // get average value\n",
        "          var avarage_value = 0.00\n",
        "          for(var i = 0; i < inds.length; i++) {\n",
        "              avarage_value = avarage_value + d1[\"value\"][inds[i]]\n",
        "          }\n",
        "          avarage_value = (avarage_value/inds.length).toFixed(2)\n",
        "\n",
        "\n",
        "          // calculate the area of the trapezoid (the sum of the two bases (we count the value as minutes) * h (difference between the dates in minutess) / 2)\n",
        "          var area = 0.00\n",
        "          for(var i = 0; i < (inds.length-1); i++) {\n",
        "              var sum_bases = d1[\"value\"][inds[i]] + d1[\"value\"][inds[i+1]] \n",
        "              var height = ((new Date(d1[\"date\"][inds[i+1]])).getTime() - (new Date(d1[\"date\"][inds[i]])).getTime()) / 60000\n",
        "\n",
        "              area = area + (sum_bases * height) / 2\n",
        "          }\n",
        "          // set the number of decimals to 2\n",
        "          area = parseFloat(area).toFixed(2);\n",
        "\n",
        "\n",
        "          // push all the data in the source of the data_table\n",
        "          d2[\"Start_date\"].push(start_date)\n",
        "          d2[\"End_date\"].push(end_date)\n",
        "          d2[\"Max_value\"].push(max_value)\n",
        "          d2[\"Average_value\"].push(avarage_value)\n",
        "          d2[\"Area\"].push(area)\n",
        "\n",
        "\n",
        "          // reset the values of the bar plot and update them (order of values is: Max Value, Avarage Value, Area)\n",
        "          d3[\"value\"] = []\n",
        "          d3[\"value\"].push(max_value)\n",
        "          d3[\"value\"].push(avarage_value)\n",
        "          d3[\"value\"].push(area)\n",
        "\n",
        "\n",
        "          // update the table and bar plot (this function notify that something has changed, and to immediately update the values and UI)\n",
        "          source_table.change.emit()\n",
        "          source_barplot.change.emit()\n",
        "        }\n",
        "        \"\"\"\n",
        "))\n",
        "\n",
        "save_button.js_on_click(CustomJS(args=dict(source_table=source_table, break_lines=break_lines), code=\"\"\"\n",
        "        // get the data from the source of the table\n",
        "        var data = source_table.data\n",
        "\n",
        "        // get the length of the list \n",
        "        var number_of_data = data[\"Start_date\"].length\n",
        "\n",
        "        // order the data\n",
        "        var start_date_list = data[\"Start_date\"]\n",
        "        var end_date_list = data[\"End_date\"]\n",
        "        var max_value_list = data[\"Max_value\"]\n",
        "        var avarage_value_list = data[\"Average_value\"]\n",
        "        var area_list = data[\"Area\"]\n",
        "\n",
        "        // fill the string with the data (while also modifying the data of date format of: hour,minute and seconds to 2 digit string)\n",
        "        var out = \"\";\n",
        "        for (var i = 0; i < number_of_data; i++) {\n",
        "          out += i+ \")\" +break_lines+ \n",
        "                 \"Start Date:    \"  +start_date_list[i]+ \"\" +break_lines+\n",
        "                 \"End Date:      \"  +end_date_list[i]+ \"\" +break_lines+\n",
        "                 \"Max Value:     \"  +max_value_list[i]+ \"\" +break_lines+\n",
        "                 \"Avarage Value: \"  +avarage_value_list[i]+ \"\" +break_lines+\n",
        "                 \"Area:          \"  +area_list[i]+ \"\" +break_lines+ \"\" +break_lines\n",
        "        }\n",
        "\n",
        "\n",
        "        // write the data in the file\n",
        "        var file = new Blob([out], {type: 'text/plain'});\n",
        "        var elem = window.document.createElement('a');\n",
        "        elem.href = window.URL.createObjectURL(file);\n",
        "        elem.download = 'selected_data.txt';\n",
        "        document.body.appendChild(elem);\n",
        "        elem.click();\n",
        "        document.body.removeChild(elem);\n",
        "    \"\"\"\n",
        "))\n",
        "\n",
        "# visualize the chart in the output\n",
        "layout = column(main_chart, row(bar_plot,  column(data_table, save_button)))\n",
        "show(layout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXiGzH3ubsQF"
      },
      "source": [
        "# Other Library used to visualize data\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzsMtRJibjHH"
      },
      "source": [
        "Test of creating the chart using various libraries...\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZPO-mU3cKR-"
      },
      "source": [
        "Draw everything in a chart using the altair library (i haven't used this library since it doesn't have any support for return the data selected)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIgHNcl2pJOj"
      },
      "source": [
        "import altair as alt\n",
        "\n",
        "brush = alt.selection_interval(encodings=['x'])\n",
        "\n",
        "color = alt.condition(brush, alt.value('blue'), alt.value('lightgray'))\n",
        "\n",
        "chart = alt.Chart(data).mark_line(point={\n",
        "    \"filled\": False,\n",
        "    \"fill\": 'white'\n",
        "    }).encode(\n",
        "        y=alt.Y('value', sort=alt.EncodingSortField('value', order='descending')),\n",
        "        x='date',\n",
        "        color=color\n",
        ").add_selection(\n",
        "    brush\n",
        ")\n",
        "\n",
        "chart "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV5B9BQacL1b"
      },
      "source": [
        "Draw everything in a chart using the Plotly library (i haven't used this library since it doesn't have any support for return the data selected, an exemption is DASH that is the framework built-on this library, but using this, require a few tweaks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXneVPkaGCrA"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure(go.Scatter(x=data.date, y=data.value, mode=\"markers+lines\"))\n",
        "\n",
        "scatter = fig.data[0]\n",
        "\n",
        "def update_point(trace, points, selector):\n",
        "  print(\"Sleeping\")\n",
        "scatter.on_click(update_point)\n",
        "\n",
        "fig.show(renderer=\"colab\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}